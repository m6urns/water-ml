{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, matthews_corrcoef, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datasets\n",
    "data_train_raw = pd.read_csv('/root/projects/water-ml/datasets/sheet_1.csv')\n",
    "data_test_raw = pd.read_csv('/root/projects/water-ml/datasets/sheet_2_3.csv')\n",
    "data_train_unlabeled = pd.read_csv('/root/projects/water-ml/datasets/sheet_3.csv')\n",
    "\n",
    "# Remove DWDS_sim_rows from data\n",
    "dwds = data_test_raw[data_test_raw['Location'] == 'DWDS Simulator (EPA, 2016)']\n",
    "\n",
    "# Drop DWDS sim data from sheets 2&3 (test_data)\n",
    "data_test = data_test_raw[data_test_raw['Location'] != 'DWDS Simulator (EPA, 2016)']\n",
    "\n",
    "# Concatenate train data and dwds data\n",
    "data_train = pd.concat([data_train_raw, dwds])\n",
    "\n",
    "# Prepare train data\n",
    "target_columns = ['Scheme', 'Sample (reference)']\n",
    "X_train = data_train_raw.drop(target_columns, axis=1)\n",
    "y_train = data_train_raw['Scheme'].map({'Stable': 1, 'Failure': 0})\n",
    "X_train.replace('ND', 0, inplace=True)\n",
    "\n",
    "# Prepare test data\n",
    "target_columns = ['Scheme', 'Sample', 'Location']\n",
    "X_test = data_test.drop(target_columns, axis=1)\n",
    "y_test = data_test['Scheme'].map({'Stable': 1, 'Failure': 0})\n",
    "X_test.replace('ND', 0, inplace=True)\n",
    "X_test.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "adasyn_oversampler = ADASYN(sampling_strategy='auto', random_state=42)\n",
    "X_train_adasyn, y_train_adasyn = adasyn_oversampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_confusion_matrix(cm, y_true, y_pred):\n",
    "#     tn, fp, fn, tp = cm.ravel()\n",
    "#     total = np.sum(cm)\n",
    "#     accuracy = (tp + tn) / total\n",
    "#     precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "#     recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "#     specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "#     f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "#     mcc = matthews_corrcoef(y_true, y_pred)\n",
    "#     print(\"Confusion Matrix:\")\n",
    "#     print(cm)\n",
    "#     print()\n",
    "#     print(f\"True Negatives (TN): {tn}\")\n",
    "#     print(f\"False Positives (FP): {fp}\")\n",
    "#     print(f\"False Negatives (FN): {fn}\")\n",
    "#     print(f\"True Positives (TP): {tp}\")\n",
    "#     print()\n",
    "#     print(f\"Accuracy: {accuracy:.3f}\")\n",
    "#     print(f\"Precision: {precision:.3f}\")\n",
    "#     print(f\"Recall: {recall:.3f}\")\n",
    "#     print(f\"Specificity: {specificity:.3f}\")\n",
    "#     print(f\"F1 Score: {f1_score:.3f}\")\n",
    "#     print(f\"Matthews Correlation Coefficient (MCC): {mcc:.3f}\")\n",
    "#     if precision == 0 and recall == 0:\n",
    "#         warnings.warn(\"Precision and Recall are both zero. F1 Score may not be meaningful.\")\n",
    "#     if tn + fp == 0:\n",
    "#         warnings.warn(\"No negative samples. Specificity may not be meaningful.\")\n",
    "\n",
    "\n",
    "# def fit_model(model, X_train, y_train, X_test, y_test):\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     cm = confusion_matrix(y_test, y_pred)\n",
    "#     print_confusion_matrix(cm, y_test, y_pred)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search for ExtraTreesClassifier with ADASYN:\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model based on Accuracy:\n",
      "Best parameters: {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Confusion Matrix:\n",
      "[[18 30]\n",
      " [ 6 96]]\n",
      "\n",
      "True Negatives (TN): 18\n",
      "False Positives (FP): 30\n",
      "False Negatives (FN): 6\n",
      "True Positives (TP): 96\n",
      "\n",
      "Accuracy: 0.760\n",
      "Precision: 0.762\n",
      "Recall: 0.941\n",
      "Specificity: 0.375\n",
      "F1 Score: 0.842\n",
      "Matthews Correlation Coefficient (MCC): 0.402\n",
      "\n",
      "Best Model based on MCC Score:\n",
      "Best parameters: {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Confusion Matrix:\n",
      "[[34 14]\n",
      " [ 7 95]]\n",
      "\n",
      "True Negatives (TN): 34\n",
      "False Positives (FP): 14\n",
      "False Negatives (FN): 7\n",
      "True Positives (TP): 95\n",
      "\n",
      "Accuracy: 0.860\n",
      "Precision: 0.872\n",
      "Recall: 0.931\n",
      "Specificity: 0.708\n",
      "F1 Score: 0.900\n",
      "Matthews Correlation Coefficient (MCC): 0.670\n"
     ]
    }
   ],
   "source": [
    "# def grid_search_augmented(X_train_adasyn, y_train_adasyn, X_test, y_test):\n",
    "#     # Frozen parameters\n",
    "#     frozen_params = {\n",
    "#         'bootstrap': [True],\n",
    "#         'criterion': ['gini'],\n",
    "#         'max_depth': [3],\n",
    "#         'max_features': ['sqrt'],\n",
    "#         'min_samples_leaf': [1],\n",
    "#         'min_samples_split': [2],\n",
    "#         'n_estimators': [50]\n",
    "#     }\n",
    "\n",
    "#     # Additional parameters to tune\n",
    "#     param_grid = {\n",
    "#         'class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "#         'ccp_alpha': [0.0, 0.1, 0.2],\n",
    "#         'max_samples': [None, 0.5, 0.7, 0.9],\n",
    "#         'oob_score': [True, False],\n",
    "#         'warm_start': [True, False],\n",
    "#         'n_jobs': [-1]\n",
    "#     }\n",
    "\n",
    "#     # Combine frozen parameters and additional parameters\n",
    "#     param_grid.update(frozen_params)\n",
    "\n",
    "#     # Define the ExtraTreesClassifier model\n",
    "#     model = ExtraTreesClassifier()\n",
    "\n",
    "#     # Define the scoring functions\n",
    "#     scoring = {\n",
    "#         'accuracy': make_scorer(accuracy_score),\n",
    "#         'mcc': make_scorer(matthews_corrcoef)\n",
    "#     }\n",
    "\n",
    "#     # Perform grid search for ADASYN\n",
    "#     print(\"Grid search for ExtraTreesClassifier with ADASYN:\")\n",
    "#     grid_search_adasyn = GridSearchCV(\n",
    "#         estimator=model,\n",
    "#         param_grid=param_grid,\n",
    "#         scoring=scoring,\n",
    "#         refit='accuracy',  # Specify the metric to use for refitting the best model\n",
    "#         cv=10,\n",
    "#         n_jobs=-1,\n",
    "#         verbose=1\n",
    "#     )\n",
    "#     grid_search_adasyn.fit(X_train_adasyn, y_train_adasyn)\n",
    "\n",
    "#     # Get the best model based on accuracy\n",
    "#     best_model_accuracy = grid_search_adasyn.best_estimator_\n",
    "#     best_params_accuracy = grid_search_adasyn.best_params_\n",
    "\n",
    "#     # Get the best model based on MCC score\n",
    "#     best_index_mcc = np.argmax(grid_search_adasyn.cv_results_['mean_test_mcc'])\n",
    "#     best_params_mcc = grid_search_adasyn.cv_results_['params'][best_index_mcc]\n",
    "#     best_model_mcc = ExtraTreesClassifier(**best_params_mcc)\n",
    "\n",
    "#     # Evaluate the best model based on accuracy\n",
    "#     print(\"\\nBest Model based on Accuracy:\")\n",
    "#     print(f\"Best parameters: {best_params_accuracy}\")\n",
    "#     fit_model(best_model_accuracy, X_train_adasyn, y_train_adasyn, X_test, y_test)\n",
    "\n",
    "#     # Evaluate the best model based on MCC score\n",
    "#     print(\"\\nBest Model based on MCC Score:\")\n",
    "#     print(f\"Best parameters: {best_params_mcc}\")\n",
    "#     fit_model(best_model_mcc, X_train_adasyn, y_train_adasyn, X_test, y_test)\n",
    "\n",
    "# # Example usage\n",
    "# grid_search_augmented(X_train_adasyn, y_train_adasyn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search for ExtraTreesClassifier with ADASYN:\n",
      "Grid search for ExtraTreesClassifier with ADASYN:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/projects/water-ml/notebooks/adasyn_extratreesclassifier.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://127.0.0.1:8080/root/projects/water-ml/notebooks/adasyn_extratreesclassifier.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel Accuracy: \u001b[39m\u001b[39m{\u001b[39;00maccuracy\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://127.0.0.1:8080/root/projects/water-ml/notebooks/adasyn_extratreesclassifier.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m# Example usage (ensure you have your dataset variables defined before calling this function)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://127.0.0.1:8080/root/projects/water-ml/notebooks/adasyn_extratreesclassifier.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m grid_search_augmented(X_train_adasyn, y_train_adasyn, X_test, y_test)\n",
      "\u001b[1;32m/root/projects/water-ml/notebooks/adasyn_extratreesclassifier.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://127.0.0.1:8080/root/projects/water-ml/notebooks/adasyn_extratreesclassifier.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# Perform the grid search\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://127.0.0.1:8080/root/projects/water-ml/notebooks/adasyn_extratreesclassifier.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mGrid search for ExtraTreesClassifier with ADASYN:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://127.0.0.1:8080/root/projects/water-ml/notebooks/adasyn_extratreesclassifier.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m grid_search_adasyn\u001b[39m.\u001b[39;49mfit(X_train_adasyn, y_train_adasyn)\n\u001b[1;32m     <a href='vscode-notebook-cell://127.0.0.1:8080/root/projects/water-ml/notebooks/adasyn_extratreesclassifier.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# Retrieve the best model based on accuracy\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://127.0.0.1:8080/root/projects/water-ml/notebooks/adasyn_extratreesclassifier.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m best_model_accuracy \u001b[39m=\u001b[39m grid_search_adasyn\u001b[39m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m~/projects/.conda/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/projects/.conda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/projects/.conda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/projects/.conda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:834\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate_candidates\u001b[39m(candidate_params, cv\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, more_results\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    833\u001b[0m     cv \u001b[39m=\u001b[39m cv \u001b[39mor\u001b[39;00m cv_orig\n\u001b[0;32m--> 834\u001b[0m     candidate_params \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(candidate_params)\n\u001b[1;32m    835\u001b[0m     n_candidates \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(candidate_params)\n\u001b[1;32m    837\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/projects/.conda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:150\u001b[0m, in \u001b[0;36mParameterGrid.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    148\u001b[0m keys, values \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mitems)\n\u001b[1;32m    149\u001b[0m \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m product(\u001b[39m*\u001b[39mvalues):\n\u001b[0;32m--> 150\u001b[0m     params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(keys, v))\n\u001b[1;32m    151\u001b[0m     \u001b[39myield\u001b[39;00m params\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def grid_search_augmented(X_train_adasyn, y_train_adasyn, X_test, y_test):\n",
    "    # Define the parameter grid\n",
    "    param_grid = {\n",
    "        'class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "        'ccp_alpha': [0.0, 0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.5],\n",
    "        'max_samples': [None, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "        'oob_score': [False, True],\n",
    "        'warm_start': [False, True],\n",
    "        'n_estimators': [10, 50, 100, 150, 200, 250, 300, 350, 400],\n",
    "        'max_depth': [None, 3, 5, 7, 10, 12, 15, 20],\n",
    "        'min_samples_split': [2, 4, 6, 8, 10, 12, 14, 16],\n",
    "        'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "        'max_features': ['sqrt', 'log2', 0.2, 0.4, 0.6, 0.8, None]\n",
    "    }\n",
    "\n",
    "    #  Define the scoring functions\n",
    "    scoring = {\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'mcc': make_scorer(matthews_corrcoef)\n",
    "    }\n",
    "\n",
    "    # Perform grid search for ADASYN\n",
    "    print(\"Grid search for ExtraTreesClassifier with ADASYN:\")\n",
    "    grid_search_adasyn = GridSearchCV(\n",
    "        estimator=ExtraTreesClassifier(),\n",
    "        param_grid=param_grid,\n",
    "        scoring=scoring,\n",
    "        refit='accuracy',  # Specify the metric to use for refitting the best model\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Perform the grid search\n",
    "    print(\"Grid search for ExtraTreesClassifier with ADASYN:\")\n",
    "    grid_search_adasyn.fit(X_train_adasyn, y_train_adasyn)\n",
    "\n",
    "    # Retrieve the best model based on accuracy\n",
    "    best_model_accuracy = grid_search_adasyn.best_estimator_\n",
    "    best_params_accuracy = grid_search_adasyn.best_params_\n",
    "\n",
    "    # Evaluate and print the best model's performance\n",
    "    print(\"\\nBest Model based on Accuracy:\")\n",
    "    print(f\"Best parameters: {best_params_accuracy}\")\n",
    "    fit_model(best_model_accuracy, X_train_adasyn, y_train_adasyn, X_test, y_test)\n",
    "\n",
    "def fit_model(model, X_train, y_train, X_test, y_test):\n",
    "    # Function to fit the model and evaluate it on the test set\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = np.mean(predictions == y_test)  # Calculate accuracy\n",
    "    print(f\"Model Accuracy: {accuracy}\")\n",
    "\n",
    "# Example usage (ensure you have your dataset variables defined before calling this function)\n",
    "grid_search_augmented(X_train_adasyn, y_train_adasyn, X_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
