{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f53f9459",
   "metadata": {},
   "source": [
    "\n",
    "# Deep Learning Model Implementation for Binary Classification\n",
    "\n",
    "This notebook implements a deep learning model for binary classification using a small numerical dataset. The model architecture will consist of dense layers with dropout and regularization to prevent overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f02848f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %conda install tensorflow\n",
    "# Necessary imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l1_l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7d19291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/miniconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load and preprocess the data\n",
    "data = pd.read_csv('/home/matt/Projects/water-ml/datasets/labeled.csv')  # Update with actual path\n",
    "data.replace('ND', 0, inplace=True)\n",
    "\n",
    "# Encoding categorical features\n",
    "categorical_columns = ['Taxa A1', 'Taxa A2', 'Taxa A3', 'Taxa A4', 'Taxa A5', 'Taxa B1', 'Taxa B2', 'Taxa B3']  # Update as needed\n",
    "for col in categorical_columns:\n",
    "    data[col] = data[col].astype(str)\n",
    "    \n",
    "encoder = OneHotEncoder(sparse=False)    \n",
    "data_encoded = pd.DataFrame(encoder.fit_transform(data[categorical_columns]))\n",
    "data_encoded.columns = encoder.get_feature_names_out(categorical_columns)\n",
    "data.drop(categorical_columns ,axis=1, inplace=True)\n",
    "data = pd.concat([data, data_encoded], axis=1)\n",
    "\n",
    "# Separating features and target variable\n",
    "X = data.drop(['Scheme', 'Sample'], axis=1)  # Update target and identifier columns as needed\n",
    "y = data['Scheme'].map({'Stable': 0, 'Failure': 1})\n",
    "\n",
    "# Normalizing the dataset\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd8298e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/miniconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     NaN\n",
       "1     NaN\n",
       "2     NaN\n",
       "3     NaN\n",
       "4     NaN\n",
       "       ..\n",
       "225   NaN\n",
       "226   NaN\n",
       "227   NaN\n",
       "228   NaN\n",
       "229   NaN\n",
       "Name: Scheme, Length: 230, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_data = pd.read_csv('/home/matt/Projects/water-ml/datasets/unlabeled.csv')  # Update with actual path\n",
    "unlabeled_data.replace('ND', 0, inplace=True)\n",
    "\n",
    "categorical_columns = ['Taxa A1', 'Taxa A2', 'Taxa A3', 'Taxa A4', 'Taxa A5', 'Taxa B1', 'Taxa B2', 'Taxa B3']\n",
    "for col in categorical_columns:\n",
    "    unlabeled_data[col] = unlabeled_data[col].astype(str)\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)    \n",
    "data_encoded = pd.DataFrame(encoder.fit_transform(unlabeled_data[categorical_columns]))\n",
    "data_encoded.columns = encoder.get_feature_names_out(categorical_columns)\n",
    "unlabeled_data.drop(categorical_columns ,axis=1, inplace=True)\n",
    "unlabeled_data = pd.concat([unlabeled_data, data_encoded], axis=1)\n",
    "\n",
    "X_unlabeled = unlabeled_data.drop(['Scheme', 'Sample'], axis=1)  # Update target and identifier columns as needed\n",
    "y_unlabeled = unlabeled_data['Scheme'].map({'Stable': 0, 'Failure': 1})\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_unlabeled_scaled = scaler.fit_transform(X_unlabeled)\n",
    "\n",
    "y_unlabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcc1ca8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BaseSampler.fit_resample() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m X_smote, y_smote \u001b[38;5;241m=\u001b[39m smote\u001b[38;5;241m.\u001b[39mfit_resample(X_train, y_train)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Balance the unlabeled data\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m X_unlabeled_smote \u001b[38;5;241m=\u001b[39m \u001b[43msmote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_unlabeled_scaled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: BaseSampler.fit_resample() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Augmenting the dataset with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# TODO: Fix the SMOTE for the unlabeled , need a y, currentl all NaN see the rnb+ impelmentation for fix\n",
    "# Balance the unlabeled data\n",
    "# X_unlabeled_smote = smote.fit_resample(X_unlabeled_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd54cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.layers import GaussianNoise\n",
    "\n",
    "def create_model(l1_rate=0.001, l2_rate=0.001, learning_rate=0.001, noise_level=0.01):\n",
    "    model = Sequential()\n",
    "    model.add(GaussianNoise(noise_level, input_shape=(X_smote.shape[1],)))\n",
    "    model.add(Dense(32, activation='relu', kernel_regularizer=l1_l2(l1=l1_rate, l2=l2_rate)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(16, activation='relu', kernel_regularizer=l1_l2(l1=l1_rate, l2=l2_rate)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5b17992",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_810823/3000101305.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "\n",
    "param_grid = {\n",
    "    'l1_rate': [0.001, 0.01, 0.1],\n",
    "    'l2_rate': [0.001, 0.01, 0.1],\n",
    "    'learning_rate': [0.001, 0.01, 0.1], \n",
    "    'noise_level': [0.01, 0.05, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90586ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-20 15:30:12.493920: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-20 15:30:12.498335: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-20 15:30:12.562660: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-20 15:30:12.598217: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-20 15:30:12.603604: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-20 15:30:12.605895: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-20 15:30:12.618556: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-20 15:30:12.619806: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-20 15:30:12.624035: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-20 15:30:12.633652: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-20 15:30:12.670913: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-20 15:30:12.698001: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-20 15:30:14.302225: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.\n",
      "2024-02-20 15:30:14.455695: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.\n",
      "2024-02-20 15:30:14.556029: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.\n",
      "2024-02-20 15:30:14.592660: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.\n",
      "2024-02-20 15:30:14.615903: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.\n",
      "2024-02-20 15:30:14.674841: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.\n",
      "2024-02-20 15:30:14.713179: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.\n",
      "2024-02-20 15:30:14.721134: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.\n",
      "2024-02-20 15:30:14.762497: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.\n",
      "2024-02-20 15:30:14.769611: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.\n",
      "2024-02-20 15:30:14.796656: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.\n",
      "2024-02-20 15:30:14.937531: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n\u001b[1;32m      3\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m grid_result \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_smote\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_smote\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=10, scoring='accuracy')\n",
    "grid_result = grid.fit(X_smote, y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2512df5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.901732 using {'l1_rate': 0.01, 'l2_rate': 0.01, 'learning_rate': 0.01, 'noise_level': 0.05}\n",
      "0.877706 (0.063573) with: {'l1_rate': 0.001, 'l2_rate': 0.001, 'learning_rate': 0.001, 'noise_level': 0.01}\n",
      "0.887446 (0.075460) with: {'l1_rate': 0.001, 'l2_rate': 0.001, 'learning_rate': 0.001, 'noise_level': 0.05}\n",
      "0.888095 (0.089538) with: {'l1_rate': 0.001, 'l2_rate': 0.001, 'learning_rate': 0.001, 'noise_level': 0.1}\n",
      "0.882900 (0.085887) with: {'l1_rate': 0.001, 'l2_rate': 0.001, 'learning_rate': 0.01, 'noise_level': 0.01}\n",
      "0.850216 (0.091181) with: {'l1_rate': 0.001, 'l2_rate': 0.001, 'learning_rate': 0.01, 'noise_level': 0.05}\n",
      "0.849784 (0.106529) with: {'l1_rate': 0.001, 'l2_rate': 0.001, 'learning_rate': 0.01, 'noise_level': 0.1}\n",
      "0.636147 (0.278322) with: {'l1_rate': 0.001, 'l2_rate': 0.001, 'learning_rate': 0.1, 'noise_level': 0.01}\n",
      "0.450216 (0.281327) with: {'l1_rate': 0.001, 'l2_rate': 0.001, 'learning_rate': 0.1, 'noise_level': 0.05}\n",
      "0.371212 (0.250367) with: {'l1_rate': 0.001, 'l2_rate': 0.001, 'learning_rate': 0.1, 'noise_level': 0.1}\n",
      "0.887662 (0.068519) with: {'l1_rate': 0.001, 'l2_rate': 0.01, 'learning_rate': 0.001, 'noise_level': 0.01}\n",
      "0.896970 (0.064182) with: {'l1_rate': 0.001, 'l2_rate': 0.01, 'learning_rate': 0.001, 'noise_level': 0.05}\n",
      "0.887662 (0.074306) with: {'l1_rate': 0.001, 'l2_rate': 0.01, 'learning_rate': 0.001, 'noise_level': 0.1}\n",
      "0.850649 (0.138190) with: {'l1_rate': 0.001, 'l2_rate': 0.01, 'learning_rate': 0.01, 'noise_level': 0.01}\n",
      "0.877922 (0.098428) with: {'l1_rate': 0.001, 'l2_rate': 0.01, 'learning_rate': 0.01, 'noise_level': 0.05}\n",
      "0.807792 (0.110010) with: {'l1_rate': 0.001, 'l2_rate': 0.01, 'learning_rate': 0.01, 'noise_level': 0.1}\n",
      "0.469264 (0.302177) with: {'l1_rate': 0.001, 'l2_rate': 0.01, 'learning_rate': 0.1, 'noise_level': 0.01}\n",
      "0.564069 (0.243428) with: {'l1_rate': 0.001, 'l2_rate': 0.01, 'learning_rate': 0.1, 'noise_level': 0.05}\n",
      "0.532035 (0.279405) with: {'l1_rate': 0.001, 'l2_rate': 0.01, 'learning_rate': 0.1, 'noise_level': 0.1}\n",
      "0.873593 (0.079560) with: {'l1_rate': 0.001, 'l2_rate': 0.1, 'learning_rate': 0.001, 'noise_level': 0.01}\n",
      "0.887662 (0.074306) with: {'l1_rate': 0.001, 'l2_rate': 0.1, 'learning_rate': 0.001, 'noise_level': 0.05}\n",
      "0.887662 (0.071752) with: {'l1_rate': 0.001, 'l2_rate': 0.1, 'learning_rate': 0.001, 'noise_level': 0.1}\n",
      "0.849351 (0.088951) with: {'l1_rate': 0.001, 'l2_rate': 0.1, 'learning_rate': 0.01, 'noise_level': 0.01}\n",
      "0.868398 (0.080784) with: {'l1_rate': 0.001, 'l2_rate': 0.1, 'learning_rate': 0.01, 'noise_level': 0.05}\n",
      "0.874242 (0.106164) with: {'l1_rate': 0.001, 'l2_rate': 0.1, 'learning_rate': 0.01, 'noise_level': 0.1}\n",
      "0.334632 (0.207070) with: {'l1_rate': 0.001, 'l2_rate': 0.1, 'learning_rate': 0.1, 'noise_level': 0.01}\n",
      "0.410823 (0.249543) with: {'l1_rate': 0.001, 'l2_rate': 0.1, 'learning_rate': 0.1, 'noise_level': 0.05}\n",
      "0.334199 (0.206723) with: {'l1_rate': 0.001, 'l2_rate': 0.1, 'learning_rate': 0.1, 'noise_level': 0.1}\n",
      "0.869048 (0.083782) with: {'l1_rate': 0.01, 'l2_rate': 0.001, 'learning_rate': 0.001, 'noise_level': 0.01}\n",
      "0.869048 (0.083782) with: {'l1_rate': 0.01, 'l2_rate': 0.001, 'learning_rate': 0.001, 'noise_level': 0.05}\n",
      "0.873810 (0.084321) with: {'l1_rate': 0.01, 'l2_rate': 0.001, 'learning_rate': 0.001, 'noise_level': 0.1}\n",
      "0.863420 (0.107026) with: {'l1_rate': 0.01, 'l2_rate': 0.001, 'learning_rate': 0.01, 'noise_level': 0.01}\n",
      "0.844589 (0.084470) with: {'l1_rate': 0.01, 'l2_rate': 0.001, 'learning_rate': 0.01, 'noise_level': 0.05}\n",
      "0.864286 (0.082966) with: {'l1_rate': 0.01, 'l2_rate': 0.001, 'learning_rate': 0.01, 'noise_level': 0.1}\n",
      "0.466667 (0.310313) with: {'l1_rate': 0.01, 'l2_rate': 0.001, 'learning_rate': 0.1, 'noise_level': 0.01}\n",
      "0.482251 (0.287416) with: {'l1_rate': 0.01, 'l2_rate': 0.001, 'learning_rate': 0.1, 'noise_level': 0.05}\n",
      "0.496537 (0.263259) with: {'l1_rate': 0.01, 'l2_rate': 0.001, 'learning_rate': 0.1, 'noise_level': 0.1}\n",
      "0.869048 (0.083782) with: {'l1_rate': 0.01, 'l2_rate': 0.01, 'learning_rate': 0.001, 'noise_level': 0.01}\n",
      "0.878355 (0.077226) with: {'l1_rate': 0.01, 'l2_rate': 0.01, 'learning_rate': 0.001, 'noise_level': 0.05}\n",
      "0.864286 (0.085656) with: {'l1_rate': 0.01, 'l2_rate': 0.01, 'learning_rate': 0.001, 'noise_level': 0.1}\n",
      "0.859740 (0.103067) with: {'l1_rate': 0.01, 'l2_rate': 0.01, 'learning_rate': 0.01, 'noise_level': 0.01}\n",
      "0.901732 (0.069650) with: {'l1_rate': 0.01, 'l2_rate': 0.01, 'learning_rate': 0.01, 'noise_level': 0.05}\n",
      "0.863853 (0.076210) with: {'l1_rate': 0.01, 'l2_rate': 0.01, 'learning_rate': 0.01, 'noise_level': 0.1}\n",
      "0.358009 (0.230733) with: {'l1_rate': 0.01, 'l2_rate': 0.01, 'learning_rate': 0.1, 'noise_level': 0.01}\n",
      "0.367965 (0.226784) with: {'l1_rate': 0.01, 'l2_rate': 0.01, 'learning_rate': 0.1, 'noise_level': 0.05}\n",
      "0.427056 (0.266942) with: {'l1_rate': 0.01, 'l2_rate': 0.01, 'learning_rate': 0.1, 'noise_level': 0.1}\n",
      "0.868831 (0.081795) with: {'l1_rate': 0.01, 'l2_rate': 0.1, 'learning_rate': 0.001, 'noise_level': 0.01}\n",
      "0.864286 (0.082966) with: {'l1_rate': 0.01, 'l2_rate': 0.1, 'learning_rate': 0.001, 'noise_level': 0.05}\n",
      "0.878355 (0.079857) with: {'l1_rate': 0.01, 'l2_rate': 0.1, 'learning_rate': 0.001, 'noise_level': 0.1}\n",
      "0.822078 (0.132728) with: {'l1_rate': 0.01, 'l2_rate': 0.1, 'learning_rate': 0.01, 'noise_level': 0.01}\n",
      "0.863203 (0.088701) with: {'l1_rate': 0.01, 'l2_rate': 0.1, 'learning_rate': 0.01, 'noise_level': 0.05}\n",
      "0.868615 (0.082796) with: {'l1_rate': 0.01, 'l2_rate': 0.1, 'learning_rate': 0.01, 'noise_level': 0.1}\n",
      "0.343723 (0.214014) with: {'l1_rate': 0.01, 'l2_rate': 0.1, 'learning_rate': 0.1, 'noise_level': 0.01}\n",
      "0.310390 (0.185128) with: {'l1_rate': 0.01, 'l2_rate': 0.1, 'learning_rate': 0.1, 'noise_level': 0.05}\n",
      "0.325108 (0.199091) with: {'l1_rate': 0.01, 'l2_rate': 0.1, 'learning_rate': 0.1, 'noise_level': 0.1}\n",
      "0.287013 (0.157674) with: {'l1_rate': 0.1, 'l2_rate': 0.001, 'learning_rate': 0.001, 'noise_level': 0.01}\n",
      "0.301299 (0.175335) with: {'l1_rate': 0.1, 'l2_rate': 0.001, 'learning_rate': 0.001, 'noise_level': 0.05}\n",
      "0.287013 (0.157674) with: {'l1_rate': 0.1, 'l2_rate': 0.001, 'learning_rate': 0.001, 'noise_level': 0.1}\n",
      "0.301299 (0.175335) with: {'l1_rate': 0.1, 'l2_rate': 0.001, 'learning_rate': 0.01, 'noise_level': 0.01}\n",
      "0.287013 (0.157674) with: {'l1_rate': 0.1, 'l2_rate': 0.001, 'learning_rate': 0.01, 'noise_level': 0.05}\n",
      "0.287013 (0.157674) with: {'l1_rate': 0.1, 'l2_rate': 0.001, 'learning_rate': 0.01, 'noise_level': 0.1}\n",
      "0.334199 (0.206723) with: {'l1_rate': 0.1, 'l2_rate': 0.001, 'learning_rate': 0.1, 'noise_level': 0.01}\n",
      "0.287013 (0.157674) with: {'l1_rate': 0.1, 'l2_rate': 0.001, 'learning_rate': 0.1, 'noise_level': 0.05}\n",
      "0.315584 (0.190303) with: {'l1_rate': 0.1, 'l2_rate': 0.001, 'learning_rate': 0.1, 'noise_level': 0.1}\n",
      "0.301299 (0.175335) with: {'l1_rate': 0.1, 'l2_rate': 0.01, 'learning_rate': 0.001, 'noise_level': 0.01}\n",
      "0.287013 (0.157674) with: {'l1_rate': 0.1, 'l2_rate': 0.01, 'learning_rate': 0.001, 'noise_level': 0.05}\n",
      "0.287013 (0.157674) with: {'l1_rate': 0.1, 'l2_rate': 0.01, 'learning_rate': 0.001, 'noise_level': 0.1}\n",
      "0.287013 (0.157674) with: {'l1_rate': 0.1, 'l2_rate': 0.01, 'learning_rate': 0.01, 'noise_level': 0.01}\n",
      "0.287013 (0.157674) with: {'l1_rate': 0.1, 'l2_rate': 0.01, 'learning_rate': 0.01, 'noise_level': 0.05}\n",
      "0.301299 (0.175335) with: {'l1_rate': 0.1, 'l2_rate': 0.01, 'learning_rate': 0.01, 'noise_level': 0.1}\n",
      "0.403463 (0.246790) with: {'l1_rate': 0.1, 'l2_rate': 0.01, 'learning_rate': 0.1, 'noise_level': 0.01}\n",
      "0.339394 (0.210785) with: {'l1_rate': 0.1, 'l2_rate': 0.01, 'learning_rate': 0.1, 'noise_level': 0.05}\n",
      "0.334632 (0.207070) with: {'l1_rate': 0.1, 'l2_rate': 0.01, 'learning_rate': 0.1, 'noise_level': 0.1}\n",
      "0.287013 (0.157674) with: {'l1_rate': 0.1, 'l2_rate': 0.1, 'learning_rate': 0.001, 'noise_level': 0.01}\n",
      "0.287013 (0.157674) with: {'l1_rate': 0.1, 'l2_rate': 0.1, 'learning_rate': 0.001, 'noise_level': 0.05}\n",
      "0.287013 (0.157674) with: {'l1_rate': 0.1, 'l2_rate': 0.1, 'learning_rate': 0.001, 'noise_level': 0.1}\n",
      "0.315584 (0.190303) with: {'l1_rate': 0.1, 'l2_rate': 0.1, 'learning_rate': 0.01, 'noise_level': 0.01}\n",
      "0.287013 (0.157674) with: {'l1_rate': 0.1, 'l2_rate': 0.1, 'learning_rate': 0.01, 'noise_level': 0.05}\n",
      "0.301299 (0.175335) with: {'l1_rate': 0.1, 'l2_rate': 0.1, 'learning_rate': 0.01, 'noise_level': 0.1}\n",
      "0.427706 (0.254947) with: {'l1_rate': 0.1, 'l2_rate': 0.1, 'learning_rate': 0.1, 'noise_level': 0.01}\n",
      "0.310390 (0.185128) with: {'l1_rate': 0.1, 'l2_rate': 0.1, 'learning_rate': 0.1, 'noise_level': 0.05}\n",
      "0.296104 (0.169266) with: {'l1_rate': 0.1, 'l2_rate': 0.1, 'learning_rate': 0.1, 'noise_level': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "# Current Best:  \n",
    "# 0.882428 (0.052831) with: {'l1_rate': 0.001, 'l2_rate': 0.1, 'learning_rate': 0.001} CV:3 noise_level=0.01\n",
    "\n",
    "# Previous Best:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
