{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f53f9459",
   "metadata": {},
   "source": [
    "\n",
    "# Deep Learning Model Implementation for Binary Classification\n",
    "\n",
    "This notebook implements a deep learning model for binary classification using a small numerical dataset. The model architecture will consist of dense layers with dropout and regularization to prevent overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f02848f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %conda install tensorflow\n",
    "# Necessary imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l1_l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d7d19291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/miniconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load and preprocess the data\n",
    "data = pd.read_csv('/home/matt/Projects/water-ml/datasets/labelled.csv')  # Update with actual path\n",
    "data.replace('ND', 0, inplace=True)\n",
    "\n",
    "# Encoding categorical features\n",
    "categorical_columns = ['Taxa A1', 'Taxa A2', 'Taxa A3', 'Taxa A4', 'Taxa A5', 'Taxa B1', 'Taxa B2', 'Taxa B3']  # Update as needed\n",
    "for col in categorical_columns:\n",
    "    data[col] = data[col].astype(str)\n",
    "    \n",
    "encoder = OneHotEncoder(sparse=False)    \n",
    "data_encoded = pd.DataFrame(encoder.fit_transform(data[categorical_columns]))\n",
    "data_encoded.columns = encoder.get_feature_names_out(categorical_columns)\n",
    "data.drop(categorical_columns ,axis=1, inplace=True)\n",
    "data = pd.concat([data, data_encoded], axis=1)\n",
    "\n",
    "# Separating features and target variable\n",
    "X = data.drop(['Scheme', 'Sample'], axis=1)  # Update target and identifier columns as needed\n",
    "y = data['Scheme'].map({'Stable': 0, 'Failure': 1})\n",
    "\n",
    "# Normalizing the dataset\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dcc1ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Augmenting the dataset with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b4fa34f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model architecture v1 (overfitting)\n",
    "# model = Sequential()\n",
    "# model.add(Dense(64, activation='relu', input_shape=(X_scaled.shape[1],), kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(32, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Adjusted Model architecture\n",
    "# model = Sequential()\n",
    "# model.add(Dense(32, activation='relu', input_shape=(X_smote.shape[1],), kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))\n",
    "# # Reduced dropout rate\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(16, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))\n",
    "# # Removed one layer to simplify the model\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2c5d278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# # Adjusting the model architecture and parameters\n",
    "# model = Sequential()\n",
    "# model.add(Dense(16, activation='relu', input_shape=(X_smote.shape[1],), kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(8, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# # Compile the model with a possibly adjusted learning rate\n",
    "# model.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Implementing Early Stopping\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# # Model training with Early Stopping\n",
    "# history = model.fit(X_smote, y_smote, epochs=100, validation_data=(X_test, y_test), callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "67463a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout\n",
    "# from tensorflow.keras.regularizers import l1_l2\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# def create_model(l1_rate=0.001, l2_rate=0.001, learning_rate=0.001):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(32, activation='relu', input_shape=(X_smote.shape[1],), kernel_regularizer=l1_l2(l1=l1_rate, l2=l2_rate)))\n",
    "#     model.add(Dropout(0.3))\n",
    "#     model.add(Dense(16, activation='relu', kernel_regularizer=l1_l2(l1=l1_rate, l2=l2_rate)))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "#     optimizer = Adam(learning_rate=learning_rate)\n",
    "#     model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cd54cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.layers import GaussianNoise\n",
    "\n",
    "def create_model(l1_rate=0.001, l2_rate=0.001, learning_rate=0.001, noise_level=0.01):\n",
    "    model = Sequential()\n",
    "    model.add(GaussianNoise(noise_level, input_shape=(X_smote.shape[1],)))\n",
    "    model.add(Dense(32, activation='relu', kernel_regularizer=l1_l2(l1=l1_rate, l2=l2_rate)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(16, activation='relu', kernel_regularizer=l1_l2(l1=l1_rate, l2=l2_rate)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a5b17992",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_579234/3737891085.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "\n",
    "param_grid = {\n",
    "    'l1_rate': [0.001, 0.01, 0.1],\n",
    "    'l2_rate': [0.001, 0.01, 0.1],\n",
    "    'learning_rate': [0.001, 0.01, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "90586ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 955us/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 932us/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 818us/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 810us/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 558us/step\n",
      "3/3 [==============================] - 0s 603us/step\n",
      "3/3 [==============================] - 0s 665us/step\n",
      "3/3 [==============================] - 0s 652us/step\n",
      "3/3 [==============================] - 0s 862us/step\n",
      "3/3 [==============================] - 0s 820us/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 933us/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 871us/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 961us/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 930us/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 877us/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 904us/step\n",
      "3/3 [==============================] - 0s 964us/step\n",
      "3/3 [==============================] - 0s 984us/step\n",
      "3/3 [==============================] - 0s 701us/step\n",
      "3/3 [==============================] - 0s 625us/step\n",
      "3/3 [==============================] - 0s 577us/step\n",
      "3/3 [==============================] - 0s 651us/step\n",
      "3/3 [==============================] - 0s 908us/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, scoring='accuracy')\n",
    "grid_result = grid.fit(X_smote, y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2512df5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.882428 using {'l1_rate': 0.001, 'l2_rate': 0.1, 'learning_rate': 0.001}\n",
      "0.854259 (0.072750) with: {'l1_rate': 0.001, 'l2_rate': 0.001, 'learning_rate': 0.001}\n",
      "0.849564 (0.076287) with: {'l1_rate': 0.001, 'l2_rate': 0.001, 'learning_rate': 0.01}\n",
      "0.778739 (0.069460) with: {'l1_rate': 0.001, 'l2_rate': 0.001, 'learning_rate': 0.1}\n",
      "0.877867 (0.078186) with: {'l1_rate': 0.001, 'l2_rate': 0.01, 'learning_rate': 0.001}\n",
      "0.797720 (0.097323) with: {'l1_rate': 0.001, 'l2_rate': 0.01, 'learning_rate': 0.01}\n",
      "0.555064 (0.230865) with: {'l1_rate': 0.001, 'l2_rate': 0.01, 'learning_rate': 0.1}\n",
      "0.882428 (0.052831) with: {'l1_rate': 0.001, 'l2_rate': 0.1, 'learning_rate': 0.001}\n",
      "0.830718 (0.086475) with: {'l1_rate': 0.001, 'l2_rate': 0.1, 'learning_rate': 0.01}\n",
      "0.320322 (0.068834) with: {'l1_rate': 0.001, 'l2_rate': 0.1, 'learning_rate': 0.1}\n",
      "0.859021 (0.080312) with: {'l1_rate': 0.01, 'l2_rate': 0.001, 'learning_rate': 0.001}\n",
      "0.854259 (0.072750) with: {'l1_rate': 0.01, 'l2_rate': 0.001, 'learning_rate': 0.01}\n",
      "0.428303 (0.178555) with: {'l1_rate': 0.01, 'l2_rate': 0.001, 'learning_rate': 0.1}\n",
      "0.863716 (0.076381) with: {'l1_rate': 0.01, 'l2_rate': 0.01, 'learning_rate': 0.001}\n",
      "0.783769 (0.131968) with: {'l1_rate': 0.01, 'l2_rate': 0.01, 'learning_rate': 0.01}\n",
      "0.320322 (0.068834) with: {'l1_rate': 0.01, 'l2_rate': 0.01, 'learning_rate': 0.1}\n",
      "0.849631 (0.086124) with: {'l1_rate': 0.01, 'l2_rate': 0.1, 'learning_rate': 0.001}\n",
      "0.830584 (0.074960) with: {'l1_rate': 0.01, 'l2_rate': 0.1, 'learning_rate': 0.01}\n",
      "0.320322 (0.068834) with: {'l1_rate': 0.01, 'l2_rate': 0.1, 'learning_rate': 0.1}\n",
      "0.320322 (0.068834) with: {'l1_rate': 0.1, 'l2_rate': 0.001, 'learning_rate': 0.001}\n",
      "0.320322 (0.068834) with: {'l1_rate': 0.1, 'l2_rate': 0.001, 'learning_rate': 0.01}\n",
      "0.320322 (0.068834) with: {'l1_rate': 0.1, 'l2_rate': 0.001, 'learning_rate': 0.1}\n",
      "0.320322 (0.068834) with: {'l1_rate': 0.1, 'l2_rate': 0.01, 'learning_rate': 0.001}\n",
      "0.320322 (0.068834) with: {'l1_rate': 0.1, 'l2_rate': 0.01, 'learning_rate': 0.01}\n",
      "0.320322 (0.068834) with: {'l1_rate': 0.1, 'l2_rate': 0.01, 'learning_rate': 0.1}\n",
      "0.320322 (0.068834) with: {'l1_rate': 0.1, 'l2_rate': 0.1, 'learning_rate': 0.001}\n",
      "0.320322 (0.068834) with: {'l1_rate': 0.1, 'l2_rate': 0.1, 'learning_rate': 0.01}\n",
      "0.320322 (0.068834) with: {'l1_rate': 0.1, 'l2_rate': 0.1, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
